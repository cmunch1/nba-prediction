{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8e4f389",
   "metadata": {},
   "source": [
    "### Production Features Pipeline - Hopsworks.ai version\n",
    "\n",
    "This notebook is run daily from a Github Action. \n",
    "\n",
    "1. It scrapes the results from the previous day's games, performs feature engineering, and saves the results back to the Feature Store at Hopsworks.ai\n",
    "\n",
    "2. It scrapes the upcoming games for today, and saves the blank records back into the Feature Store at Hopsworks.ai so that they can be accessed by the model for the prediction service via the streamlit app.\n",
    "\n",
    "**Note:**\n",
    "There are two options for webscraping in this notebook. \n",
    "Set the 'WEBSCRAPER' variable to either 'SCRAPINGANT' or 'SELENIUM' to choose which version to run.\n",
    "\n",
    "1. SCRAPINGANT: Uses a webscraping service with a Python API, ScrapingAnt, which handles all the proxy server issues, but does require an account. The free account allows for 1000 page requests, which is more than enough for this project. Proxies are required when running this notebook from a Github Action or otherwise key data will fail to be scraped from NBA.com. \n",
    "\n",
    "2. SELENIUM: This option does not currently integrate proxy servers into the webscraping process, which can cause issues when scraping from certain locations, in particular Github Actions. For occasional use from local machines, this option may work fine, but you may need to setup a proxy server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select web scraper; 'SCRAPINGANT' or 'SELENIUM'\n",
    "# SCRAPINGANT requires a subscription but includes a proxy server\n",
    "\n",
    "WEBSCRAPER = 'SCRAPINGANT'\n",
    "#WEBSCRAPER = 'SELENIUM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c58a3-8738-42ad-be18-8e13c171108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import hopsworks\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "from pathlib import Path  #for Windows/Linux compatibility\n",
    "\n",
    "# change working directory to project root when running from notebooks folder to make it easier to import modules\n",
    "# and to access sibling folders\n",
    "os.chdir('..') \n",
    "\n",
    " \n",
    "from src.webscraping import (\n",
    "    get_new_games,\n",
    "    activate_web_driver,\n",
    "    get_todays_matchups,\n",
    ")\n",
    "\n",
    "from src.data_processing import (\n",
    "    process_games,\n",
    "    add_TARGET,\n",
    ")\n",
    "\n",
    "from src.feature_engineering import (\n",
    "    process_features,\n",
    ")\n",
    "\n",
    "from src.hopsworks_utils import (\n",
    "    save_feature_names,\n",
    "    convert_feature_names,\n",
    ")\n",
    "\n",
    "from src.constants import (\n",
    "    FEATURE_GROUP_VERSION,\n",
    ")\n",
    "\n",
    "DATAPATH = Path(r'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e754aaa7",
   "metadata": {},
   "source": [
    "**Load API keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124d9cf-8a24-4a04-bf68-c7dc7ff1d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    HOPSWORKS_API_KEY = os.environ['HOPSWORKS_API_KEY']\n",
    "except:\n",
    "    raise Exception('Set environment variable HOPSWORKS_API_KEY')\n",
    "\n",
    "# if scrapingant is chosen then set the api key, otherwise load the selenium webdriver\n",
    "if WEBSCRAPER == 'SCRAPINGANT':\n",
    "    try:\n",
    "        SCRAPINGANT_API_KEY = os.environ['SCRAPINGANT_API_KEY']\n",
    "    except:\n",
    "        raise Exception('Set environment variable SCRAPINGANT_API_KEY')\n",
    "    driver = None\n",
    "    \n",
    "elif WEBSCRAPER == 'SELENIUM':\n",
    "    driver = activate_web_driver('chromium')\n",
    "    SCRAPINGANT_API_KEY = \"\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f29eac3-4b58-4a07-bdba-b4c72cb491ec",
   "metadata": {},
   "source": [
    "**Scrape New Completed Games and Format Them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81e4bd-45fa-44f6-bbb3-7d1821c56963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_new = get_new_games(SCRAPINGANT_API_KEY, driver)\n",
    "\n",
    "if df_new.empty:\n",
    "    print('No new games to process')\n",
    "\n",
    "    # determine what season we are in currently\n",
    "    today = datetime.now(timezone('EST')) #nba.com uses US Eastern Standard Time\n",
    "    if today.month >= 10:\n",
    "        SEASON = today.year\n",
    "    else:\n",
    "        SEASON = today.year - 1\n",
    "else:\n",
    "\n",
    "    # get the SEASON of the last game in the database\n",
    "    # this will used when constructing rows for prediction\n",
    "    SEASON = df_new['SEASON'].max()\n",
    "\n",
    "    df_new\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfd78420",
   "metadata": {},
   "source": [
    "**Retrieve todays games**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afa738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve list of teams playing today\n",
    "\n",
    "# get today's games on NBA schedule\n",
    "matchups, game_ids = get_todays_matchups(SCRAPINGANT_API_KEY, driver)\n",
    "\n",
    "if matchups is None:\n",
    "    print('No games today')\n",
    "else:\n",
    "    print(matchups)\n",
    "    print(game_ids)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3aef12e5",
   "metadata": {},
   "source": [
    "**Close Webdriver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "if WEBSCRAPER == 'SELENIUM':\n",
    "    driver.close() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a4abb60",
   "metadata": {},
   "source": [
    "**Check if anything is going on in the season**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b720127",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (df_new.empty) and (matchups is None):\n",
    "    print('No new games to process')\n",
    "    exit()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a43729ef",
   "metadata": {},
   "source": [
    "**Create Rows for Today's Games with Empty Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat today's matchups to the new games dataframe\n",
    "\n",
    "if matchups is None:\n",
    "    print('No games going on. Nothing to do.')\n",
    "    exit()    \n",
    "\n",
    "else:\n",
    "\n",
    "    df_today = df_new.drop(df_new.index) #empty copy of df_new with same columns\n",
    "    for i, matchup in enumerate(matchups):\n",
    "        game_details = {'HOME_TEAM_ID': matchup[1], \n",
    "                        'VISITOR_TEAM_ID': matchup[0], \n",
    "                        'GAME_DATE_EST': datetime.now(timezone('EST')).strftime(\"%Y-%m-%d\"), \n",
    "                        'GAME_ID': int(game_ids[i]),                       \n",
    "                        'SEASON': SEASON,\n",
    "                        } \n",
    "        game_details_df = pd.DataFrame(game_details, index=[i])\n",
    "        # append to new games dataframe\n",
    "        df_today = pd.concat([df_today, game_details_df], ignore_index = True)\n",
    "\n",
    "    #blank rows will be filled with 0 to prevent issues with feature engineering\n",
    "    df_today = df_today.fillna(0) \n",
    "\n",
    "    df_today\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb1180-ea38-452c-9afd-73eea3ee7e17",
   "metadata": {},
   "source": [
    "**Access Feature Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69a88c-691e-4f8d-b68e-e79f5582a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "\n",
    "# HOPSWORKS can be kinda buggy and has been throwing a lot of errors recently or even just failing to return data\n",
    "# so I'm adding a try/except block to retry the query if it fails\n",
    "tries = 5\n",
    "\n",
    "for i in range(tries):\n",
    "    \n",
    "    try:\n",
    "        fs = project.get_feature_store()\n",
    "    except KeyError as e:\n",
    "        if i < tries - 1: # i is zero indexed\n",
    "            time.sleep(30)\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError('HOPSWORKS failed to connect')\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256829e7",
   "metadata": {},
   "source": [
    "**Access Feature Group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d97e5-0888-42c3-a9b1-97c9ef2b7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOPSWORKS can be kinda buggy and has been throwing a lot of errors recently or even just failing to return data\n",
    "# so I'm adding a try/except block to retry the query if it fails\n",
    "tries = 5\n",
    "\n",
    "for i in range(tries):\n",
    "    \n",
    "    try:\n",
    "        rolling_stats_fg = fs.get_feature_group(\n",
    "        name=\"rolling_stats\",\n",
    "        version=FEATURE_GROUP_VERSION,\n",
    "        )\n",
    "    except KeyError as e:\n",
    "        if i < tries - 1: # i is zero indexed\n",
    "            time.sleep(30)\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError('HOPSWORKS failed to connect')\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0acc836a",
   "metadata": {},
   "source": [
    "**Query Old Data Needed for Feature Engineering of New Data**\n",
    "\n",
    "To generate features like rolling averages for the new games, older data from previous games is needed since some of the rolling averages might extend back 15 or 20 games or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FEATURES = ['game_date_est',\n",
    " 'game_id',\n",
    " 'home_team_id',\n",
    " 'visitor_team_id',\n",
    " 'season',\n",
    " 'pts_home',\n",
    " 'fg_pct_home',\n",
    " 'ft_pct_home',\n",
    " 'fg3_pct_home',\n",
    " 'ast_home',\n",
    " 'reb_home',\n",
    " 'pts_away',\n",
    " 'fg_pct_away',\n",
    " 'ft_pct_away',\n",
    " 'fg3_pct_away',\n",
    " 'ast_away',\n",
    " 'reb_away',\n",
    " 'home_team_wins',\n",
    "]\n",
    "\n",
    "ds_query = rolling_stats_fg.select(BASE_FEATURES)\n",
    "\n",
    "# HOPSWORKS can be kinda buggy and has been throwing a lot of errors recently or even just failing to return data\n",
    "# so I'm adding a try/except block to retry the query if it fails\n",
    "tries = 5\n",
    "\n",
    "for i in range(tries):\n",
    "    for j in range(tries):\n",
    "        try:\n",
    "            df_old = ds_query.read()\n",
    "            #df_old = ds_query.read(read_options={\"use_hive\": True})\n",
    "        except KeyError as e:\n",
    "            if j < tries - 1: \n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            else:\n",
    "                raise ValueError('HOPSWORKS failed to connect')\n",
    "        break\n",
    "\n",
    "    if df_old.empty:\n",
    "        if i < tries - 1: \n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            raise ValueError('HOPSWORKS failed to return data')\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "df_old\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3185e1e1",
   "metadata": {},
   "source": [
    "**Convert Feature Names back to original mixed case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fc2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hopsworks converts all feature names to lowercase, and for code reuse, we need to convert them back\n",
    "df_old = convert_feature_names(df_old)\n",
    "df_old\n",
    "df_old[df_old['PTS_home'] == 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9453ea9a",
   "metadata": {},
   "source": [
    "**Update Yesterday's Matchup Predictions with New Final Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out games that are pending final results\n",
    "# (these were the rows used for prediction yesterday)\n",
    "# and then update these with the new results\n",
    "\n",
    "\n",
    "# one approach is to simply drop the rows that were used for prediction yesterday\n",
    "# which are games that have 0 points for home team\n",
    "# and then append the new rows to the dataframe\n",
    "df_old = df_old[df_old['PTS_home'] != 0]\n",
    "df_old = pd.concat([df_old, df_new], ignore_index = True)\n",
    "\n",
    "df_old"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f169f4ce",
   "metadata": {},
   "source": [
    "**Add Today's Matchups for Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bf4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if matchups is None:\n",
    "    print('No games today')\n",
    "    df_combined = df_old\n",
    "else:\n",
    "    df_combined = pd.concat([df_old, df_today], ignore_index = True)\n",
    "    df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835625fc-be47-4a8f-a532-02dc8e79363e",
   "metadata": {},
   "source": [
    "**Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577f0e2-39f7-4cef-9f8f-e687cb73f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = process_games(df_combined) \n",
    "df_combined = add_TARGET(df_combined)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb588e",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19484061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering to add: \n",
    "    # rolling averages of key stats, \n",
    "    # win/lose streaks, \n",
    "    # home/away streaks, \n",
    "    # specific matchup (team X vs team Y) rolling averages and streaks\n",
    "\n",
    "df_combined = process_features(df_combined)\n",
    "\n",
    "\n",
    "\n",
    "#fix type conversion issues with hopsworks\n",
    "df_combined['TARGET'] = df_combined['TARGET'].astype('int16')\n",
    "df_combined['HOME_TEAM_WINS'] = df_combined['HOME_TEAM_WINS'].astype('int16')\n",
    "\n",
    "df_combined\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67eea1e5",
   "metadata": {},
   "source": [
    "**Insert New Data into Feature Group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76fc400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOPSWORKS can be kinda buggy and has been throwing a lot of errors recently or even just failing to return data\n",
    "# so I'm adding a try/except block to retry the query if it fails\n",
    "tries = 5\n",
    "\n",
    "for i in range(tries):\n",
    "    \n",
    "    try:\n",
    "        rolling_stats_fg.insert(df_combined, overwrite = True, write_options={\"wait_for_job\" : False})\n",
    "    except KeyError as e:\n",
    "        if i < tries - 1: \n",
    "            time.sleep(30)\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError('HOPSWORKS failed to connect')\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ac7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure there are no duplicate games were inadvertently added\n",
    "df_combined[df_combined.duplicated(subset=['GAME_ID'], keep=False)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4655998f62ad965cbd25df51edb717f2326f5df53d53899f0ae604225aa5ae06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
