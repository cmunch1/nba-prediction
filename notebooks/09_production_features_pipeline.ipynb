{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8e4f389",
   "metadata": {},
   "source": [
    "### Production Features Pipeline - CSV Version\n",
    "\n",
    "This notebook is run daily from a Github Action. \n",
    "\n",
    "1. It scrapes the results from the previous day's games, performs feature engineering, and saves the results back to a csv file. This is an alternative version of the pipeline that DOES NOT utilize the Hopsworks.ai Feature Store and is less dependent on other platforms.\n",
    "\n",
    "2. It scrapes the upcoming games for today, and saves the blank records back into the csv file so that they can be accessed by the model for the prediction.\n",
    "\n",
    "**Note:**\n",
    "There are two options for webscraping in this notebook. \n",
    "Set the 'WEBSCRAPER' variable to either 'SCRAPINGANT' or 'SELENIUM' to choose which version to run.\n",
    "\n",
    "1. SCRAPINGANT: Uses a webscraping service with a Python API, ScrapingAnt, which handles all the proxy server issues, but does require an account. The free account allows for 1000 page requests, which is more than enough for this project. Proxies are required when running this notebook from a Github Action or otherwise key data will fail to be scraped from NBA.com. \n",
    "\n",
    "2. SELENIUM: This option does not currently integrate proxy servers into the webscraping process, which can cause issues when scraping from certain locations, in particular Github Actions. For occasional use from local machines, this option may work fine, but you may need to setup a proxy server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select web scraper; 'SCRAPINGANT' or 'SELENIUM'\n",
    "# SCRAPINGANT requires a subscription but includes a proxy server\n",
    "\n",
    "WEBSCRAPER = 'SCRAPINGANT'\n",
    "#WEBSCRAPER = 'SELENIUM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c58a3-8738-42ad-be18-8e13c171108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import hopsworks\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "from pathlib import Path  #for Windows/Linux compatibility\n",
    "\n",
    "# change working directory to project root when running from notebooks folder to make it easier to import modules\n",
    "# and to access sibling folders\n",
    "os.chdir('..') \n",
    "\n",
    " \n",
    "from src.webscraping import (\n",
    "    get_new_games,\n",
    "    activate_web_driver,\n",
    "    get_todays_matchups,\n",
    ")\n",
    "\n",
    "from src.data_processing import (\n",
    "    process_games,\n",
    "    add_TARGET,\n",
    ")\n",
    "\n",
    "from src.feature_engineering import (\n",
    "    process_features,\n",
    ")\n",
    "\n",
    "from src.dashboard_processing import (\n",
    "    NBADataProcessor,\n",
    ")\n",
    "\n",
    "from src.google_drive_utils import (\n",
    "    upload_to_drive,\n",
    ")\n",
    "\n",
    "DATAPATH = Path(r'data')\n",
    "GOOGLE_FOLDER_ID = \"1y5AfF3KZ8FGzxr2pyuncXJpKWEa5j-CL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e754aaa7",
   "metadata": {},
   "source": [
    "**Load API keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124d9cf-8a24-4a04-bf68-c7dc7ff1d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#try:\n",
    "#    HOPSWORKS_API_KEY = os.environ['HOPSWORKS_API_KEY']\n",
    "#except:\n",
    "#    raise Exception('Set environment variable HOPSWORKS_API_KEY')\n",
    "\n",
    "\n",
    "# if scrapingant is chosen then set the api key, otherwise load the selenium webdriver\n",
    "if WEBSCRAPER == 'SCRAPINGANT':\n",
    "    try:\n",
    "        SCRAPINGANT_API_KEY = os.environ['SCRAPINGANT_API_KEY']\n",
    "    except:\n",
    "        raise Exception('Set environment variable SCRAPINGANT_API_KEY')\n",
    "    driver = None\n",
    "    \n",
    "elif WEBSCRAPER == 'SELENIUM':\n",
    "    driver = activate_web_driver('chromium')\n",
    "    SCRAPINGANT_API_KEY = \"\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f29eac3-4b58-4a07-bdba-b4c72cb491ec",
   "metadata": {},
   "source": [
    "**Scrape New Completed Games and Format Them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81e4bd-45fa-44f6-bbb3-7d1821c56963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_new = get_new_games(SCRAPINGANT_API_KEY, driver)\n",
    "\n",
    "if df_new.empty:\n",
    "    print('No new games to process')\n",
    "\n",
    "    # determine what season we are in currently\n",
    "    today = datetime.now(timezone('EST')) #nba.com uses US Eastern Standard Time\n",
    "    if today.month >= 10:\n",
    "        SEASON = today.year\n",
    "    else:\n",
    "        SEASON = today.year - 1\n",
    "else:\n",
    "\n",
    "    # get the SEASON of the last game in the database\n",
    "    # this will used when constructing rows for prediction\n",
    "    SEASON = df_new['SEASON'].max()\n",
    "\n",
    "    df_new\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfd78420",
   "metadata": {},
   "source": [
    "**Retrieve todays games**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afa738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve list of teams playing today\n",
    "\n",
    "# get today's games on NBA schedule\n",
    "matchups, game_ids = get_todays_matchups(SCRAPINGANT_API_KEY, driver)\n",
    "\n",
    "if matchups is None:\n",
    "    print('No games today')\n",
    "else:\n",
    "    print(matchups)\n",
    "    print(game_ids)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3aef12e5",
   "metadata": {},
   "source": [
    "**Close Webdriver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "if WEBSCRAPER == 'SELENIUM':\n",
    "    driver.close() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a4abb60",
   "metadata": {},
   "source": [
    "**Check if anything is going on in the season**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b720127",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (df_new.empty) and (matchups is None):\n",
    "    print('No new games to process')\n",
    "    #exit()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a43729ef",
   "metadata": {},
   "source": [
    "**Create Rows for Today's Games with Empty Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat today's matchups to the new games dataframe\n",
    "\n",
    "if matchups is None:\n",
    "    print('No games going on. Nothing to do.')\n",
    "    #exit()    \n",
    "\n",
    "else:\n",
    "\n",
    "    df_today = df_new.drop(df_new.index) #empty copy of df_new with same columns\n",
    "    for i, matchup in enumerate(matchups):\n",
    "        game_details = {'HOME_TEAM_ID': matchup[1], \n",
    "                        'VISITOR_TEAM_ID': matchup[0], \n",
    "                        'GAME_DATE_EST': datetime.now(timezone('EST')).strftime(\"%Y-%m-%d\"), \n",
    "                        'GAME_ID': int(game_ids[i]),                       \n",
    "                        'SEASON': SEASON,\n",
    "                        } \n",
    "        game_details_df = pd.DataFrame(game_details, index=[i])\n",
    "        # append to new games dataframe\n",
    "        df_today = pd.concat([df_today, game_details_df], ignore_index = True)\n",
    "\n",
    "    #blank rows will be filled with 0 to prevent issues with feature engineering\n",
    "    df_today = df_today.fillna(0) \n",
    "\n",
    "    df_today\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0acc836a",
   "metadata": {},
   "source": [
    "**Query Old Data Needed for Feature Engineering of New Data**\n",
    "\n",
    "To generate features like rolling averages for the new games, older data from previous games is needed since some of the rolling averages might extend back 15 or 20 games or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_old = pd.read_csv(DATAPATH / 'games.csv')\n",
    "\n",
    "df_old\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9453ea9a",
   "metadata": {},
   "source": [
    "**Update Yesterday's Matchup Predictions with New Final Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out games that are pending final results\n",
    "# (these were the rows used for prediction yesterday)\n",
    "# and then update these with the new results\n",
    "\n",
    "\n",
    "# one approach is to simply drop the rows that were used for prediction yesterday\n",
    "# which are games that have 0 points for home team\n",
    "# and then append the new rows to the dataframe\n",
    "df_old = df_old[df_old['PTS_home'] != 0]\n",
    "df_old = pd.concat([df_old, df_new], ignore_index = True)\n",
    "\n",
    "\n",
    "# save the new games to the database\n",
    "df_old.to_csv(DATAPATH / 'games.csv', index=False)\n",
    "\n",
    "df_old"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f169f4ce",
   "metadata": {},
   "source": [
    "**Add Today's Matchups for Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bf4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if matchups is None:\n",
    "    print('No games today')\n",
    "    df_combined = df_old\n",
    "else:\n",
    "    df_combined = pd.concat([df_old, df_today], ignore_index = True)\n",
    "    df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835625fc-be47-4a8f-a532-02dc8e79363e",
   "metadata": {},
   "source": [
    "**Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577f0e2-39f7-4cef-9f8f-e687cb73f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = process_games(df_combined) \n",
    "df_combined = add_TARGET(df_combined)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb588e",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19484061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering to add: \n",
    "    # rolling averages of key stats, \n",
    "    # win/lose streaks, \n",
    "    # home/away streaks, \n",
    "    # specific matchup (team X vs team Y) rolling averages and streaks\n",
    "\n",
    "df_combined = process_features(df_combined)\n",
    "\n",
    "\n",
    "\n",
    "#fix type conversion issues with hopsworks\n",
    "df_combined['TARGET'] = df_combined['TARGET'].astype('int16')\n",
    "df_combined['HOME_TEAM_WINS'] = df_combined['HOME_TEAM_WINS'].astype('int16')\n",
    "\n",
    "# save file\n",
    "df_combined.to_csv(DATAPATH / 'games_engineered.csv', index=False)\n",
    "\n",
    "\n",
    "df_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dfafcd",
   "metadata": {},
   "source": [
    "**Process Data for Convenient Dashboarding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6166b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = NBADataProcessor()\n",
    "exported_files = processor.export_data_for_dashboard()\n",
    "\n",
    "print(\"\\nData Processing Complete!\")\n",
    "print(f\"Files exported for Dashboards:\")\n",
    "for key, value in exported_files.items():\n",
    "    if value:\n",
    "        print(f\"- {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350b578",
   "metadata": {},
   "source": [
    "**Upload to Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3229f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files_to_upload = [\n",
    "    DATAPATH / 'games_dashboard.csv',\n",
    "    DATAPATH / 'season_summary_stats.csv',\n",
    "    DATAPATH / 'running_accuracy_metrics.csv'\n",
    "]\n",
    "upload_to_drive(files_to_upload, GOOGLE_FOLDER_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4655998f62ad965cbd25df51edb717f2326f5df53d53899f0ae604225aa5ae06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
